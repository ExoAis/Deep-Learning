{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "202ff664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bdf8faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "display_step = 30\n",
    "batch_size = 32\n",
    "crit_repeats = 5\n",
    "learning_rate = 0.002\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "lambda_ = 10\n",
    "z_dim = 128\n",
    "w_dim = 496\n",
    "hidden_dim = 256\n",
    "img_channels = 3\n",
    "image_size = 1024\n",
    "n_images = batch_size\n",
    "size = (3, 1024, 1024)\n",
    "numClasses = 0\n",
    "device = 'cuda'\n",
    "loss = 'W'\n",
    "trained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33d66b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'FFHQ Faces'\n",
    "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e373bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ImageFolder(DATA_DIR, transform = T.Compose([\n",
    "    T.Resize(image_size),\n",
    "    T.CenterCrop(image_size),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(*stats)])\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    train_ds, \n",
    "    batch_size, \n",
    "    shuffle = True, \n",
    "    num_workers = 2, \n",
    "    pin_memory = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdb83b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor, num_images = 25, size = (1, 28, 28)):\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a50c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise(n_examples, z_dim, device = 'cpu'):\n",
    "    noise = torch.randn(n_examples, z_dim, device = device)\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e342bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.Linear):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d253730",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MappingNetwork(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim, w_dim):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(z_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, w_dim),\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        out = self.seq(noise)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84cf08a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InjectNoise(nn.Module):\n",
    "    def __init__(self, im_dim):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(\n",
    "            torch.randn(im_dim)[None, :, None, None]\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        n_shape = (X.shape[0], 1, X.shape[2], X.shape[3])\n",
    "        noise = torch.randn(n_shape, device = X.device)\n",
    "        out = X + self.weights * noise\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f954a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaIN(nn.Module):\n",
    "    def __init__(self, im_dim, w_dim):\n",
    "        super().__init__()\n",
    "        self.instance_norm = nn.InstanceNorm2d(im_dim)\n",
    "        self.style_scale = nn.Linear(w_dim, im_dim)\n",
    "        self.style_shift = nn.Linear(w_dim, im_dim)\n",
    "    def forward(self, X, inter_noise):\n",
    "        out_1 = self.instance_norm(X)\n",
    "        s_scale = self.style_scale(inter_noise)[:, :, None, None]\n",
    "        s_shift = self.style_shift(inter_noise)[:, :, None, None]\n",
    "        out = s_scale * out_1 + s_shift\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02ee9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, starting_size, w_dim, use_upsample = True):\n",
    "        super().__init__()\n",
    "        self.use_upsample = use_upsample\n",
    "        if self.use_upsample:\n",
    "            self.upsample = nn.Upsample((starting_size), mode = 'bilinear')\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding = 1)\n",
    "        self.inject_noise = InjectNoise(out_channels)\n",
    "        self.adaIn = AdaIN(out_channels, w_dim)\n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "    def forward(self, X, inter_noise):\n",
    "        if self.use_upsample:\n",
    "            X = self.upsample(X)\n",
    "        out_1 = self.conv(X)\n",
    "        out_2 = self.inject_noise(out_1)\n",
    "        out_3 = self.activation(out_2)\n",
    "        out = self.adaIn(out_3, inter_noise)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b571ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, w_dim, z_dim, hidden_dim, alpha = 0.2, use_upsample = True):\n",
    "        super().__init__()\n",
    "        self.starting_constant = nn.Parameter(torch.randn(1, in_channels, 4, 4))\n",
    "        self.use_upsample = use_upsample\n",
    "        self.mapping_network = MappingNetwork(z_dim, hidden_dim, w_dim)\n",
    "        self.block_1 = GeneratorBlock(in_channels, hidden_dim, kernel_size, 4, w_dim, use_upsample = False)\n",
    "        self.block_2 = GeneratorBlock(hidden_dim, hidden_dim, kernel_size, 8, w_dim)\n",
    "        self.block_3 = GeneratorBlock(hidden_dim, hidden_dim, kernel_size, 16, w_dim)\n",
    "        self.block_4 = GeneratorBlock(hidden_dim, hidden_dim, kernel_size, 32, w_dim)\n",
    "        self.block_5 = GeneratorBlock(hidden_dim, hidden_dim, kernel_size, 64, w_dim)\n",
    "        self.block_6 = GeneratorBlock(hidden_dim, hidden_dim, kernel_size, 128, w_dim)\n",
    "        self.block_7 = GeneratorBlock(hidden_dim, hidden_dim, kernel_size, 256, w_dim)\n",
    "        self.block_8 = GeneratorBlock(hidden_dim, hidden_dim, kernel_size, 512, w_dim)\n",
    "        self.block_9 = GeneratorBlock(hidden_dim, hidden_dim, kernel_size, 1024, w_dim)\n",
    "        self.block_to_image_1 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size = 1)\n",
    "        self.block_to_image_2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size = 1)\n",
    "        self.block_to_image_3 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size = 1)\n",
    "        self.block_to_image_4 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size = 1)\n",
    "        self.block_to_image_5 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size = 1)\n",
    "        self.block_to_image_6 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size = 1)\n",
    "        self.block_to_image_7 = nn.Conv2d(hidden_dim, out_channels, kernel_size = 1)\n",
    "        self.block_to_image_8 = nn.Conv2d(hidden_dim, out_channels, kernel_size = 1)\n",
    "        self.alpha = alpha\n",
    "    def upsample_to_match_size(self, smaller_image, bigger_image):\n",
    "        return F.interpolate(smaller_image, size = bigger_image.shape[-2:], mode = 'bilinear')\n",
    "    def forward(self, noise):\n",
    "        X = self.starting_constant\n",
    "        out_1 = self.mapping_network(noise)\n",
    "        out_2 = self.block_1(X, out_1)\n",
    "        \n",
    "        out_3 = self.block_2(out_2, out_1) # 8x8\n",
    "        upsampled_1 = self.block_to_image_1(out_3)\n",
    "        out_4 = self.block_3(out_3, out_1) # 16x16\n",
    "        upsampled_2 = self.block_to_image_2(out_4)\n",
    "        upsampled_B1 = self.upsample_to_match_size(upsampled_1, upsampled_2)\n",
    "        interpolated_1 = (self.alpha) * (upsampled_2) + (1 - self.alpha) * (upsampled_B1)\n",
    "        \n",
    "        out_5 = self.block_4(interpolated_1, out_1) # 32x32\n",
    "        upsampled_3 = self.block_to_image_3(out_5)\n",
    "        out_6 = self.block_5(out_5, out_1) # 64x64\n",
    "        upsampled_4 = self.block_to_image_4(out_6)\n",
    "        upsampled_B2 = self.upsample_to_match_size(upsampled_3, upsampled_4)\n",
    "        interpolated_2 = (self.alpha) * (upsampled_4) + (1 - self.alpha) * (upsampled_B2)\n",
    "        \n",
    "        out_7 = self.block_6(interpolated_2, out_1) # 128x128\n",
    "        upsampled_5 = self.block_to_image_5(out_7)\n",
    "        out_8 = self.block_7(out_7, out_1) # 256x256\n",
    "        upsampled_6 = self.block_to_image_6(out_8)\n",
    "        upsampled_B3 = self.upsample_to_match_size(upsampled_5, upsampled_6)\n",
    "        interpolated_3 = (self.alpha) * (upsampled_6) + (1 - self.alpha) * (upsampled_B3)\n",
    "        \n",
    "        out_9 = self.block_8(interpolated_3, out_1) # 512x512\n",
    "        upsampled_7 = self.block_to_image_7(out_9)\n",
    "        out_10 = self.block_9(out_9, out_1) # 1024x1024\n",
    "        upsampled_8 = self.block_to_image_8(out_10)\n",
    "        upsampled_B4 = self.upsample_to_match_size(upsampled_7, upsampled_8)\n",
    "        interpolated_4 = (self.alpha) * (upsampled_8) + (1 - self.alpha) * (upsampled_B4)\n",
    "        \n",
    "        return interpolated_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e61dba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CriticBlock(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, kernel_size = 4, stride = 2):\n",
    "        super().__init__()\n",
    "        self.conv2d_1 = nn.Conv2d(input_channels, output_channels, kernel_size, stride)\n",
    "        self.batchnorm2d_1 = nn.BatchNorm2d(output_channels)\n",
    "        self.activation = nn.LeakyReLU(0.2, inplace = True)\n",
    "    def forward(self, X):\n",
    "        X = self.conv2d_1(X)\n",
    "        X = self.batchnorm2d_1(X)\n",
    "        X = self.activation(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "519c3c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, img_channels, hidden_dims, alpha):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.conv_1 = nn.Conv2d(img_channels, hidden_dims, kernel_size = 1)\n",
    "        self.block_1 = CriticBlock(hidden_dims, hidden_dims * 2)\n",
    "        self.block_2 = CriticBlock(hidden_dims * 2, hidden_dims * 4)\n",
    "        self.block_3 = CriticBlock(hidden_dims * 4, hidden_dims * 8)\n",
    "        self.block_4 = CriticBlock(hidden_dims * 8, hidden_dims * 16)\n",
    "        self.block_5 = CriticBlock(hidden_dims * 16, hidden_dims * 32)\n",
    "        self.block_6 = CriticBlock(hidden_dims * 32, hidden_dims * 64)\n",
    "        self.conv_2 = nn.Conv2d(hidden_dim * 64, 1, kernel_size = 4, stride = 2)\n",
    "    def forward(self, img):\n",
    "        out_1 = self.conv_1(img)\n",
    "        \n",
    "        out_2 = self.block_1(out_1)\n",
    "        out_3 = self.block_2(out_2)\n",
    "        out_4 = self.block_3(out_3)\n",
    "        out_5 = self.block_4(out_4)\n",
    "        out_6 = self.block_5(out_5)\n",
    "        out_7 = self.block_6(out_6)\n",
    "        \n",
    "        out_8 = self.conv_2(out_7)\n",
    "        \n",
    "        return out_8.view(len(out_8), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcc52196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(crit, real, fake, epsilon):\n",
    "    interpolated_img = real * epsilon + fake * (1 - epsilon)\n",
    "    pred = crit(interpolated_img)\n",
    "    grad = torch.autograd.grad(\n",
    "        inputs = interpolated_img,\n",
    "        outputs = pred,\n",
    "        grad_outputs=torch.ones_like(pred), \n",
    "        create_graph=True,\n",
    "        retain_graph=True        \n",
    "    )[0]\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f79f7395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(gradient):\n",
    "    gradient = gradient.view(len(gradient), -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)   \n",
    "    penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb07add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss_gen(fake_pred):\n",
    "    return -torch.mean(fake_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "583c8e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss_crit(fake_pred, real_pred, penalty, lambda_ = 0.1):\n",
    "    crit_loss = torch.mean(fake_pred) - torch.mean(real_pred) + torch.mean(lambda_ * (penalty))\n",
    "    return crit_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5159c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(generator, n_examples, z_dim, conditional, numClasses = 0, num_images = 25, size = (1, 28, 28), labels = [], device = 'cpu'):\n",
    "    if conditional == True:\n",
    "        if len(labels) == 0:\n",
    "            for i in range(num_images):\n",
    "                labels.append(random.randint(0, numClasses - 1))\n",
    "            labels = torch.Tensor(labels).to(device)\n",
    "        elif len(labels) == 1:\n",
    "            labels = torch.floor(labels[0] + torch.rand(num_images, ))\n",
    "            labels = labels.to(device)\n",
    "        labels = labels.to(torch.int64)\n",
    "        one_hot = oneHotEncode(numClasses, labels)\n",
    "        pred_noise = generate_noise(n_examples, z_dim, device)\n",
    "        pred_noise_labels = combineVectors(pred_noise, one_hot)\n",
    "        pred_images = generator(pred_noise_labels)\n",
    "    else:\n",
    "        pred_noise = generate_noise(n_examples, z_dim, device)\n",
    "        pred_images = generator(pred_noise)\n",
    "    show_tensor_images(pred_images, num_images, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "723b9cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StyleGAN(trained, generator, critic, generator_optimizer, critic_optimizer, epochs, display_step, img_channels, crit_repeats, learning_rate, beta_1, beta_2, lambda_, z_dim, w_dim, hidden_dim, shape, dataloader, loss, device):\n",
    "    if trained == False:\n",
    "        gen = Generator(img_channels, img_channels, 3, w_dim, z_dim, hidden_dim).to(device)\n",
    "        crit = Critic(img_channels, hidden_dim, alpha = 0.2).to(device)\n",
    "        gen_optimizer = torch.optim.Adam(gen.parameters(), lr = learning_rate, betas = (beta_1, beta_2))\n",
    "        crit_optimizer = torch.optim.Adam(crit.parameters(), lr = learning_rate, betas = (beta_1, beta_2))\n",
    "    \n",
    "    elif trained == True:\n",
    "        gen = generator\n",
    "        crit = critic\n",
    "        gen_optimizer = generator_optimizer\n",
    "        crit_optimizer = critic_optimizer\n",
    "\n",
    "\n",
    "    if trained == False:\n",
    "        gen = gen.apply(weights_init)\n",
    "        crit = crit.apply(weights_init)\n",
    "    \n",
    "    if loss == 'BCE':\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    cur_step = 0\n",
    "    generator_losses = []\n",
    "    critic_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        for real, labels in tqdm(dataloader):\n",
    "            if epoch % 30 == 0 and epoch != 0 and gen.alpha != 1 and crit.alpha != 1:\n",
    "                gen.alpha += 0.1\n",
    "                crit.alpha += 0.1\n",
    "            cur_batch_size = len(real)\n",
    "            real = real.to(device)\n",
    "            mean_iteration_critic_loss = 0\n",
    "            if loss == 'W':\n",
    "                for _ in range(crit_repeats):\n",
    "                    crit_optimizer.zero_grad()\n",
    "                    fake_noise = generate_noise(cur_batch_size, z_dim, device = device)\n",
    "                    epsilon = torch.rand(len(real), 1, 1, 1, device = device, requires_grad = True)\n",
    "                    fake_imgs = gen(fake_noise)\n",
    "                    fake_pred = crit(fake_imgs)\n",
    "                    real_pred = crit(real)\n",
    "                    grad = get_gradient(crit, real, fake_imgs, epsilon)\n",
    "                    penalty = gradient_penalty(grad)\n",
    "                    crit_loss = wasserstein_loss_crit(fake_pred, real_pred, penalty, lambda_)\n",
    "                    mean_iteration_critic_loss += crit_loss.item() / crit_repeats\n",
    "                    critic_losses += [mean_iteration_critic_loss]\n",
    "                    crit_loss.backward(retain_graph = True)\n",
    "                    crit_optimizer.step()\n",
    "                cur_step += 1\n",
    "                \n",
    "                gen_optimizer.zero_grad()\n",
    "                fake_noise_1 = generate_noise(cur_batch_size, z_dim, device = device)\n",
    "                fake_imgs_1 = gen(fake_noise_1)\n",
    "                fake_pred_1 = crit(fake_imgs_1)\n",
    "                gen_loss = wasserstein_loss_gen(fake_pred_1)\n",
    "                gen_loss.backward(retain_graph = True)\n",
    "                gen_optimizer.step()\n",
    "                generator_losses += [gen_loss.item()]\n",
    "                \n",
    "            elif loss == 'BCE':\n",
    "                crit_optimizer.zero_grad()\n",
    "                fake_noise = generate_noise(cur_batch_size, z_dim, device = device)\n",
    "                fake_imgs = gen(fake_noise)\n",
    "                fake_pred = crit(fake_imgs)\n",
    "                real_pred = crit(real)\n",
    "                crit_loss_fake = criterion(fake_pred, torch.zeros_like(fake_pred))\n",
    "                crit_loss_real = criterion(real_pred, torch.ones_like(real_pred))\n",
    "                crit_loss = (crit_loss_fake + crit_loss_real) / 2\n",
    "                critic_losses += [crit_loss.item()]\n",
    "                crit_loss.backward(retain_graph = True)\n",
    "                crit_optimizer.step()\n",
    "                cur_step += 1\n",
    "                \n",
    "                gen_optimizer.zero_grad()\n",
    "                fake_pred_1 = crit(fake_imgs)\n",
    "                gen_loss = criterion(fake_pred_1, torch.ones_like(fake_pred_1))\n",
    "                gen_loss.backward(retain_graph = True)\n",
    "                gen_optimizer.step()\n",
    "                generator_losses += [gen_loss.item()]\n",
    "            \n",
    "            if cur_step % display_step == 0 and cur_step > 0:\n",
    "                gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
    "                crit_mean = sum(critic_losses[-display_step:]) / display_step\n",
    "                print(f\"Epoch {epoch}, step {cur_step}: Generator loss: {gen_mean}, critic loss: {crit_mean}\")\n",
    "                show_tensor_images(fake_imgs, size = shape)\n",
    "                show_tensor_images(real, size = shape)\n",
    "                step_bins = 20\n",
    "                num_examples = (len(generator_losses) // step_bins) * step_bins\n",
    "                plt.plot(\n",
    "                    range(num_examples // step_bins), \n",
    "                    torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                    label=\"Generator Loss\"\n",
    "                )\n",
    "                plt.plot(\n",
    "                    range(num_examples // step_bins), \n",
    "                    torch.Tensor(critic_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                    label=\"Critic Loss\"\n",
    "                )\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "    return gen, crit, gen_optimizer, crit_optimizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
