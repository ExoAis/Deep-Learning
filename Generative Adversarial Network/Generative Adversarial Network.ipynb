{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d17fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import random\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7331b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor, num_images = 25, size = (1, 28, 28)):\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e30374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineVectors(v1, v2):\n",
    "    return torch.cat((v1, v2), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "622fee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncode(numClasses, labels):\n",
    "    return nn.functional.one_hot(labels, numClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d78f08da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputDimensions(z_dim, shape, numClasses):\n",
    "    generator_input_dim = z_dim + numClasses\n",
    "    discriminator_input_dim = shape[0] + numClasses\n",
    "    return generator_input_dim, discriminator_input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cef29060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise(n_examples, z_dim, device = 'cpu'):\n",
    "    noise = torch.randn(n_examples, z_dim, device = device)\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93815620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b86e4352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, img_channels = 1, hidden_dims = 64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.gen = nn.Sequential (\n",
    "            self.make_gen_block(z_dim, hidden_dims * 4),\n",
    "            self.make_gen_block(hidden_dims * 4, hidden_dims * 2, kernel_size = 4, stride = 1),\n",
    "            self.make_gen_block(hidden_dims * 2, hidden_dims),\n",
    "            self.make_gen_block(hidden_dims, img_channels, kernel_size = 4, final_layer = True)\n",
    "        )\n",
    "    def make_gen_block(self, input_channels, output_channels, kernel_size = 3, stride = 2, final_layer = False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "    def unsqueeze_noise(self, noise):\n",
    "        return noise.view(len(noise), self.z_dim, 1, 1)\n",
    "    def forward(self, noise):\n",
    "        noise_in = self.unsqueeze_noise(noise)\n",
    "        return self.gen(noise_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38aa6ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, img_channels = 1, hidden_dims = 64):\n",
    "        super(Critic, self).__init__()\n",
    "        self.crit = nn.Sequential (\n",
    "            self.make_crit_block(img_channels, hidden_dims),\n",
    "            self.make_crit_block(hidden_dims, hidden_dims * 2),\n",
    "            self.make_crit_block(hidden_dims * 2, 1, final_layer = True)\n",
    "        )\n",
    "    def make_crit_block(self, input_channels, output_channels, kernel_size = 4, stride = 2, final_layer = False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.LeakyReLU(0.2, inplace = True)\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride)\n",
    "            )\n",
    "    def forward(self, img):\n",
    "        img_ = self.crit(img)\n",
    "        return img_.view(len(img_), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92a18b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(crit, real, fake, epsilon):\n",
    "    interpolated_img = real * epsilon + fake * (1 - epsilon)\n",
    "    pred = crit(interpolated_img)\n",
    "    grad = torch.autograd.grad(\n",
    "        inputs = interpolated_img,\n",
    "        outputs = pred,\n",
    "        grad_outputs=torch.ones_like(pred), \n",
    "        create_graph=True,\n",
    "        retain_graph=True        \n",
    "    )[0]\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbe54d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(gradient):\n",
    "    gradient = gradient.view(len(gradient), -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)   \n",
    "    penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68ec0607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss_gen(fake_pred):\n",
    "    return -torch.mean(fake_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48670e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss_crit(fake_pred, real_pred, penalty, lambda_ = 0.1):\n",
    "    crit_loss = torch.mean(fake_pred) - torch.mean(real_pred) + torch.mean(lambda_ * (penalty))\n",
    "    return crit_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdda6f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(generator, n_examples, z_dim, conditional, numClasses = 0, num_images = 25, size = (1, 28, 28), labels = [], device = 'cpu'):\n",
    "    if conditional == True:\n",
    "        if len(labels) == 0:\n",
    "            for i in range(num_images):\n",
    "                labels.append(random.randint(0, numClasses - 1))\n",
    "            labels = torch.Tensor(labels).to(device)\n",
    "        elif len(labels) == 1:\n",
    "            labels = torch.floor(labels[0] + torch.rand(num_images, ))\n",
    "            labels = labels.to(device)\n",
    "        labels = labels.to(torch.int64)\n",
    "        one_hot = oneHotEncode(numClasses, labels)\n",
    "        pred_noise = generate_noise(n_examples, z_dim, device)\n",
    "        pred_noise_labels = combineVectors(pred_noise, one_hot)\n",
    "        pred_images = generator(pred_noise_labels)\n",
    "    else:\n",
    "        pred_noise = generate_noise(n_examples, z_dim, device)\n",
    "        pred_images = generator(pred_noise)\n",
    "    show_tensor_images(pred_images, num_images, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d26783b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GAN(training_set, trained, generator, critic, generator_optimizer, critic_optimizer, epochs, display_step, img_channels, conditional, crit_repeats, learning_rate, beta_1, beta_2, lambda_, z_dim, shape, numClasses, dataloader, loss, device):\n",
    "    if trained == False:\n",
    "        if conditional == True:\n",
    "            generator_input_dim, discriminator_im_chan = getInputDimensions(z_dim, shape, numClasses)\n",
    "            gen = Generator(generator_input_dim, img_channels).to(device)\n",
    "            crit = Critic(discriminator_im_chan).to(device)\n",
    "        else:\n",
    "            gen = Generator(z_dim, img_channels).to(device)\n",
    "            crit = Critic(img_channels).to(device)\n",
    "\n",
    "        gen_optimizer = torch.optim.Adam(gen.parameters(), lr = learning_rate, betas = (beta_1, beta_2))\n",
    "        crit_optimizer = torch.optim.Adam(crit.parameters(), lr = learning_rate, betas = (beta_1, beta_2))\n",
    "    \n",
    "    elif trained == True:\n",
    "        gen = generator\n",
    "        crit = critic\n",
    "        gen_optimizer = generator_optimizer\n",
    "        crit_optimizer = critic_optimizer\n",
    "\n",
    "\n",
    "    if trained == False:\n",
    "        gen = gen.apply(weights_init)\n",
    "        crit = crit.apply(weights_init)\n",
    "    \n",
    "    if loss == 'BCE':\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    cur_step = 0\n",
    "    generator_losses = []\n",
    "    critic_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        for real, labels in tqdm(dataloader):\n",
    "            cur_batch_size = len(real)\n",
    "            real = real.to(device)\n",
    "            if conditional == True:\n",
    "                one_hot = oneHotEncode(numClasses, labels.to(device)) \n",
    "                image_one_hot_labels = one_hot[:, :, None, None]\n",
    "                image_one_hot_labels = image_one_hot_labels.repeat(1, 1, shape[1], shape[2])\n",
    "            mean_iteration_critic_loss = 0\n",
    "            if loss == 'W':\n",
    "                for _ in range(crit_repeats):\n",
    "                    crit_optimizer.zero_grad()\n",
    "                    fake_noise = generate_noise(cur_batch_size, z_dim, device = device)\n",
    "                    epsilon = torch.rand(len(real), 1, 1, 1, device = device, requires_grad = True)\n",
    "                    if conditional == True:\n",
    "                        fake_noise_labels = combineVectors(fake_noise, one_hot)\n",
    "                        fake_imgs = gen(fake_noise_labels)\n",
    "                        fake_imgs_and_labels = combineVectors(fake_imgs.detach(), image_one_hot_labels)\n",
    "                        real_imgs_and_labels = combineVectors(real, image_one_hot_labels)\n",
    "                        fake_pred = crit(fake_imgs_and_labels)\n",
    "                        real_pred = crit(real_imgs_and_labels)\n",
    "                        grad = get_gradient(crit, real_imgs_and_labels, fake_imgs_and_labels, epsilon)\n",
    "                    else:\n",
    "                        fake_imgs = gen(fake_noise)\n",
    "                        fake_pred = crit(fake_imgs)\n",
    "                        real_pred = crit(real)\n",
    "                        grad = get_gradient(crit, real, fake_imgs, epsilon)\n",
    "                    penalty = gradient_penalty(grad)\n",
    "                    crit_loss = wasserstein_loss_crit(fake_pred, real_pred, penalty, lambda_)\n",
    "                    mean_iteration_critic_loss += crit_loss.item() / crit_repeats\n",
    "                    critic_losses += [mean_iteration_critic_loss]\n",
    "                    crit_loss.backward(retain_graph = True)\n",
    "                    crit_optimizer.step()\n",
    "                cur_step += 1\n",
    "                \n",
    "                gen_optimizer.zero_grad()\n",
    "                fake_noise_1 = generate_noise(cur_batch_size, z_dim, device = device)\n",
    "                if conditional == True:\n",
    "                    fake_noise_labels_1 = combineVectors(fake_noise_1, one_hot)\n",
    "                    fake_imgs_1 = gen(fake_noise_labels_1)\n",
    "                    fake_imgs_1 = combineVectors(fake_imgs_1, image_one_hot_labels)\n",
    "                else:\n",
    "                    fake_imgs_1 = gen(fake_noise_1)\n",
    "                fake_pred_1 = crit(fake_imgs_1)\n",
    "                gen_loss = wasserstein_loss_gen(fake_pred_1)\n",
    "                gen_loss.backward(retain_graph = True)\n",
    "                gen_optimizer.step()\n",
    "                generator_losses += [gen_loss.item()]\n",
    "                \n",
    "            elif loss == 'BCE':\n",
    "                crit_optimizer.zero_grad()\n",
    "                fake_noise = generate_noise(cur_batch_size, z_dim, device = device)\n",
    "                if conditional == True:\n",
    "                    fake_noise_labels = combineVectors(fake_noise, one_hot)\n",
    "                    fake_imgs = gen(fake_noise_labels)\n",
    "                    fake_imgs_and_labels = combineVectors(fake_imgs.detach(), image_one_hot_labels)\n",
    "                    real_imgs_and_labels = combineVectors(real, image_one_hot_labels)\n",
    "                    fake_pred = crit(fake_imgs_and_labels)\n",
    "                    real_pred = crit(real_imgs_and_labels)\n",
    "                else:\n",
    "                    fake_imgs = gen(fake_noise)\n",
    "                    fake_pred = crit(fake_imgs)\n",
    "                    real_pred = crit(real)\n",
    "                crit_loss_fake = criterion(fake_pred, torch.zeros_like(fake_pred))\n",
    "                crit_loss_real = criterion(real_pred, torch.ones_like(real_pred))\n",
    "                crit_loss = (crit_loss_fake + crit_loss_real) / 2\n",
    "                critic_losses += [crit_loss.item()]\n",
    "                crit_loss.backward(retain_graph = True)\n",
    "                crit_optimizer.step()\n",
    "                cur_step += 1\n",
    "                \n",
    "                gen_optimizer.zero_grad()\n",
    "                if conditional == True:\n",
    "                    fake_noise_labels_1 = combineVectors(fake_imgs, image_one_hot_labels)\n",
    "                    fake_pred_1 = crit(fake_noise_labels_1)\n",
    "                else:\n",
    "                    fake_pred_1 = crit(fake_imgs)\n",
    "                gen_loss = criterion(fake_pred_1, torch.ones_like(fake_pred_1))\n",
    "                gen_loss.backward(retain_graph = True)\n",
    "                gen_optimizer.step()\n",
    "                generator_losses += [gen_loss.item()]\n",
    "            \n",
    "            if cur_step % display_step == 0 and cur_step > 0:\n",
    "                gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
    "                crit_mean = sum(critic_losses[-display_step:]) / display_step\n",
    "                print(f\"Epoch {epoch}, step {cur_step}: Generator loss: {gen_mean}, critic loss: {crit_mean}\")\n",
    "                show_tensor_images(fake_imgs, size = shape)\n",
    "                show_tensor_images(real, size = shape)\n",
    "                step_bins = 20\n",
    "                num_examples = (len(generator_losses) // step_bins) * step_bins\n",
    "                plt.plot(\n",
    "                    range(num_examples // step_bins), \n",
    "                    torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                    label=\"Generator Loss\"\n",
    "                )\n",
    "                plt.plot(\n",
    "                    range(num_examples // step_bins), \n",
    "                    torch.Tensor(critic_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                    label=\"Critic Loss\"\n",
    "                )\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "    return gen, crit, gen_optimizer, crit_optimizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
